---
title: "A Bulk Experiment"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A Bulk Experiment}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Dependencies
```{r setup}
library(disize)
library(curl)
library(R.utils)
library(data.table)
```

# The Dataset

This dataset consists of a purified macrophage subtype("Mac2", supposedly in 
an 'activated' state) that has been partitioned into four groups exposed to 
different conditions. The authors offer this information on how the samples 
were processed:

> The sorted Mac2 cells were divided into four groups and stimulated at the 3-h time point with the same concentrations as previously described. Then, the RNA was extracted using the RNeasy Plus Micro Kit as per manufacturer instructions. Poly(A)mRNA was isolated using mRNA Capture Beads 2.0 (Yeasen Cat.12629ES, CHN) with two rounds of purification, followed by RNA fragmentation with magnesium ions at 94°C (Yeasen Cat.12340ES97, CHN). RNA sequencing library preparation was performed using the TruSeq RNA Library Prep Kit v2 (Illumina). Sequencing was carried out as paired-end 2×150 bp (PE150) on an Illumina Novaseq™ X Plus (LC-Bio Technologies).

The TruSeq RNA Library Prep Kit involves "tagging" transcripts with barcodes 
that identify distinct samples, allowing all prepared cDNA libraries to 
be pooled together before sequencing. Since batch-effects are usually 
attributed to separate sequencing runs, then we expect very small 
batch-effects to be present in this dataset (even though some 
sample preparation was done prior to this pooling).

Let us test this hypothesis:

# Downloading The Data

```{r}
# Download counts and construct metadata
counts_path <- curl::curl_download(
    url = "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE273924&format=file&file=GSE273924%5Fraw%5Fcounts%2Etsv%2Egz",
    destfile = paste0(tempdir(), "/counts.tsv.gz")
)
counts <- data.table::fread(counts_path)

metadata <- data.frame(
    "sample_id" = c(colnames(counts)[-1]),
    "condition" = factor(rep(c("control", "lps", "nelps", "ne"), each = 3)),
    "batch_id" = factor(rep(c("batch-1", "batch-2", "batch-3", "batch-4"), each = 3))
)

# Coerce to formatted matrix
gene_names <- counts$gene_id
counts <- t(as.matrix(counts[,-1]))
colnames(counts) <- gene_names
```

# Running `disize`

The `metadata` contains the information for the experimental design:

```{r}
print(metadata)
```

For this dataset, the study was primarily interested in the effect of 
`condition` on expression, thus the formula we would input into `disize` is:

```{r}
design_formula <- ~ condition
```

We can finally run `disize` to get the estimated size factors:

```{r}
(size_factors <- disize(design_formula, counts, metadata))
```

Evidently the batch-effect is indeed small! The third batch seems to have been
processed slightly worse, but the estimated size factors are close together 
(within ~0.1).

We can confirm these estimates by rerunning `disize` with a larger `n_feats`:

```{r}
(size_factors_2 <- disize(design_formula, counts, metadata, n_feats = 15000))
```

Indeed the estimates remain largely the same.