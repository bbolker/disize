---
title: "A Bulk Experiment"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A Bulk Experiment}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Dependencies
```{r setup}
library(disize)
library(curl)
library(R.utils)
library(data.table)
```

# The dataset

This dataset consists of a purified macrophage subtype("Mac2", supposedly in
an 'activated' state) that has been partitioned into four groups exposed to
different conditions. The authors offer this information on how the samples
were processed:

> The sorted Mac2 cells were divided into four groups and stimulated at the 3-h time point with the same concentrations as previously described. Then, the RNA was extracted using the RNeasy Plus Micro Kit as per manufacturer instructions. Poly(A)mRNA was isolated using mRNA Capture Beads 2.0 (Yeasen Cat.12629ES, CHN) with two rounds of purification, followed by RNA fragmentation with magnesium ions at 94°C (Yeasen Cat.12340ES97, CHN). RNA sequencing library preparation was performed using the TruSeq RNA Library Prep Kit v2 (Illumina). Sequencing was carried out as paired-end 2×150 bp (PE150) on an Illumina Novaseq™ X Plus (LC-Bio Technologies).

The TruSeq RNA Library Prep Kit involves "tagging" transcripts with barcodes
that identify distinct *samples*, allowing all prepared cDNA libraries to
be pooled together before sequencing. Since batch-effects are usually
attributed to separate sequencing runs, then we expect very small
batch-effects to be present in this dataset if we define a "batch" as the unit
subjected to RNA extraction(and all further processing).

Let us test this hypothesis:

# Downloading the data

```{r}
# Download counts and construct metadata
counts_path <- curl::curl_download(
    url = "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE273924&format=file&file=GSE273924%5Fraw%5Fcounts%2Etsv%2Egz",
    destfile = paste0(tempdir(), "/counts.tsv.gz")
)
counts <- data.table::fread(counts_path)

metadata <- data.frame(
    "sample_id" = c(colnames(counts)[-1]),
    "condition" = factor(rep(c("control", "lps", "nelps", "ne"), each = 3))
)

# Coerce to formatted matrix
gene_names <- counts$gene_id
counts <- t(as.matrix(counts[,-1]))
colnames(counts) <- gene_names
```

# Running `disize`

The `metadata` contains the information for the experimental design:

```{r}
print(metadata)
```

For this dataset, the study was primarily interested in the effect of
`condition` on expression, thus the formula we would input into `disize` is:

```{r}
design_formula <- ~ condition
```

We can finally run `disize` to get the estimated size factors:

```{r}
size_factors <- disize(
    design_formula,
    counts,
    metadata,
    batch_name = "sample_id"
)
print(size_factors)
```

Evidently the batch-effect is indeed small across most samples! The samples
"NELPS1" and "NELPS2" seem to have been processed slightly worse, but otherwise
the estimated size factors are approximately the same (within ~0.1).

We can confirm these estimates by rerunning `disize` with a larger `n_feats`:

```{r}
size_factors_2 <- disize(
    design_formula,
    counts,
    metadata,
    batch_name = "sample_id",
    n_feats = 15000
)
print(size_factors_2)
```

Indeed the estimates remain largely the same.

# Downstream analysis

WIP
